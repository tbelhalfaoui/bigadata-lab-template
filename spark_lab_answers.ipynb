{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "spark_lab.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ivauvqar5hbQ",
        "jlSlJz3_rui9",
        "RGrzPDNTrujB",
        "OYHPkBnErujC",
        "qF-w8eqcrujH",
        "HsKOCC3grujK",
        "8UcRwMQ0rujL",
        "EAWzxCZbrujR"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivauvqar5hbQ"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlSlJz3_rui9"
      },
      "source": [
        "## Spark session and context"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhxdoEjlr1Pr"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuxhgTEArujA"
      },
      "source": [
        "import pyspark\n",
        "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGrzPDNTrujB"
      },
      "source": [
        "## Spark Web UI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbUrKvCMx85H"
      },
      "source": [
        "!pip install pyngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ftkf6H_AwCFo"
      },
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "for tunnel in ngrok.get_tunnels():\n",
        "  ngrok.disconnect(tunnel.public_url)\n",
        "ngrok.connect(4040).public_url"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGNVFZw2y7fv"
      },
      "source": [
        "## Download the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H29bAgq08y_"
      },
      "source": [
        "!wget https://www.ncei.noaa.gov/pub/data/uscrn/products/hourly02/snapshots/CRNH0203-202101180550.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiRE5P982y2c"
      },
      "source": [
        "!unzip CRNH0203-202101180550.zip -d data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYHPkBnErujC"
      },
      "source": [
        "# Introduction to RDD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwZoXlp0rujC"
      },
      "source": [
        "numbers = sc.parallelize(range(1000000))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FxQShWkrujD"
      },
      "source": [
        "numbers.take(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTyqTwZqrujF"
      },
      "source": [
        "numbers.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBZRb5XMrujF"
      },
      "source": [
        "numbers = sc.parallelize(range(1000000)).setName(\"numbers\").cache()\n",
        "numbers.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsVDVZ3RrujG"
      },
      "source": [
        "numbers.take(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J30PsCqdrujG"
      },
      "source": [
        "numbers = sc.parallelize(range(1000000)).repartition(20).setName(\"numbers3\").cache()\n",
        "numbers.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qF-w8eqcrujH"
      },
      "source": [
        "# First MapReduce exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik7SvULFrujH"
      },
      "source": [
        "### Sum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWdpukxarujI"
      },
      "source": [
        "numbers.reduce(\n",
        "    lambda x, y: x + y\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TumVuLEOrujI"
      },
      "source": [
        "numbers.sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgVPpSpmrujI"
      },
      "source": [
        "### Average"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWM4nTerrujJ"
      },
      "source": [
        "total, count = numbers.map(\n",
        "    lambda x: (x, 1)\n",
        ").reduce(\n",
        "    lambda a, b: (a[0] + b[0], a[1] + b[1])\n",
        ")\n",
        "\n",
        "total / count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iXp7Dl1rujJ"
      },
      "source": [
        "numbers.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsKOCC3grujK"
      },
      "source": [
        "### Maximum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW_5icgxrujK"
      },
      "source": [
        "numbers.reduce(lambda x, y: x if x >= y else y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3ZGJnPUrujK"
      },
      "source": [
        "numbers.reduce(max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj7_7nTKrujL"
      },
      "source": [
        "numbers.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UcRwMQ0rujL"
      },
      "source": [
        "# Real-life RDD example: temperatures dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkqbEhHxrujM"
      },
      "source": [
        "### Load the data in an RDD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyfqY2DnrujM"
      },
      "source": [
        "header = sc.textFile(\"data/HEADERS.txt\").map(lambda row: row.strip().split()).collect()[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grtO1i6c5yT4"
      },
      "source": [
        "!head data/2020/CRNH0203-2020-NY_Ithaca_13_E.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4GZD0k5rujM"
      },
      "source": [
        "weather_rdd = sc.textFile(\"data/2020/*.txt\").map(lambda row: row.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSV-520zrujN"
      },
      "source": [
        "weather_rdd.cache().count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJKDa8KFAjMW"
      },
      "source": [
        "### Maximum temperature per measurment station"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BZsq8mKrujP"
      },
      "source": [
        "index_station = header.index(\"WBANNO\")\n",
        "index_temperature = header.index(\"T_HR_AVG\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYFP7IpjApzN"
      },
      "source": [
        "temperature_maxima = weather_rdd.map(\n",
        "    lambda row: (row[index_station], float(row[index_temperature]))\n",
        ").reduceByKey(\n",
        "    lambda a, b: max(a, b)\n",
        ").collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zV9J6K6arujO"
      },
      "source": [
        "### Average temperatures per place"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlSHZgoyDgB_"
      },
      "source": [
        "#### Two-pass solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyYnR-FxDYOG"
      },
      "source": [
        "temperature_sums = weather_rdd.map(\n",
        "    lambda row: (row[index_station], float(row[index_temperature]))\n",
        ").reduceByKey(\n",
        "    lambda a, b: a + b\n",
        ").collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EI8OG0y3EJpa"
      },
      "source": [
        "temperature_counts = weather_rdd.map(\n",
        "    lambda row: (row[index_station], 1)\n",
        ").reduceByKey(\n",
        "    lambda a, b: a + b\n",
        ").collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq_b-tWMEOIW"
      },
      "source": [
        "temperature_sums = dict(temperature_sums)\n",
        "temperature_counts = dict(temperature_counts)\n",
        "temperature_averages = {}\n",
        "\n",
        "for station in temperature_sums.keys():\n",
        "    temperature_averages[station] = temperature_sums[station] / temperature_counts[station]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzfVfNYYE6ua"
      },
      "source": [
        "#### Single-pass solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6hM44YZrujP"
      },
      "source": [
        "temperature_averages = weather_rdd.map(\n",
        "    lambda row: (row[index_station], (float(row[index_temperature]), 1))\n",
        ").reduceByKey(\n",
        "    lambda a, b: (a[0] + b[0], a[1] + b[1])\n",
        ").map(\n",
        "    lambda x: (x[0], x[1][0] / x[1][1])\n",
        ").collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1QPF1NyrujN"
      },
      "source": [
        "### Temperatures histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bANGit46rujN"
      },
      "source": [
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_037-ZBrujN"
      },
      "source": [
        "counts = weather_rdd.map(\n",
        "    lambda row: (float(row[index_temperature]), 1)\n",
        ").reduceByKey(\n",
        "    lambda a, b: a + b\n",
        ").collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILG59zehrujO"
      },
      "source": [
        "x, y = zip(*sorted(counts)[1:])\n",
        "plt.bar(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qTq2MqWrujO"
      },
      "source": [
        "counts = weather_rdd.map(\n",
        "    lambda row: float(row[index_temperature])\n",
        ").countByValue()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GznLd2V9rujQ"
      },
      "source": [
        "### Average, min and max temperature per place - in a single pass!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZJD-4NvrujQ"
      },
      "source": [
        "temperature_stats = weather_rdd.map(\n",
        "    lambda row: (\n",
        "        row[index_station],\n",
        "        (\n",
        "            1,\n",
        "            float(row[index_temperature]),\n",
        "            float(row[index_temperature]),\n",
        "            float(row[index_temperature]),\n",
        "        )\n",
        "    )\n",
        ").filter(\n",
        "    lambda t: t[1][1] > -9999.0\n",
        ").reduceByKey(\n",
        "    lambda a, b: (\n",
        "        a[0] + b[0],       # running count\n",
        "        a[1] + b[1],       # running sum\n",
        "        min(a[2], b[2]),   # running minimum\n",
        "        max(a[3], b[3]),   # running maximum\n",
        "    )\n",
        ").map(\n",
        "    lambda t: (\n",
        "        t[1][1] / t[1][0],  # average\n",
        "        t[1][2],            # minimum\n",
        "        t[1][3],            # maximum\n",
        "    )\n",
        ").collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAWzxCZbrujR"
      },
      "source": [
        "# Spark SQL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZWKJtMcrujR"
      },
      "source": [
        "## From RDD to DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP5q6Qs6rujR"
      },
      "source": [
        "products_rdd = sc.parallelize([\n",
        "    {'name': 'iPhone', 'price': 800.},\n",
        "    {'name': 'Galaxy', 'price': 799.},\n",
        "    {'name': 'Huawei', 'price': 789.},\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9irSnj5trujS"
      },
      "source": [
        "from pyspark.sql import Row"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPEqPOjrrujS"
      },
      "source": [
        "products_rdd = sc.parallelize([\n",
        "    Row(name='iPhone', price=800.),\n",
        "    Row(name='Galaxy', price=799.),\n",
        "    Row(name='Huawei', price=789.),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJebvpLTrujS"
      },
      "source": [
        "products_df = products_rdd.toDF()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMvl11hArujT"
      },
      "source": [
        "products_df.toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPNbGm0JrujT"
      },
      "source": [
        "## Temperatures dataset: Spark SQL version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z8iNIk5rujT"
      },
      "source": [
        "weather_df = weather_rdd.toDF(header)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRSMONJQKmEh"
      },
      "source": [
        "weather_df.limit(10).toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qglrJ2DtrujU"
      },
      "source": [
        "weather_df.cache().count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ocLTo_8lrujU"
      },
      "source": [
        "weather_df.sample(withReplacement=True, fraction=0.0001).toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_7EjKKZrujU"
      },
      "source": [
        "weather_df = weather_df.withColumn(\"T_HR_AVG\", weather_df[\"T_HR_AVG\"].cast(\"float\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1PxK2rmrujV"
      },
      "source": [
        "temperature_averages = weather_df.groupBy(\"WBANNO\").mean(\"T_HR_AVG\").toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik5EciL5rujV"
      },
      "source": [
        "## Query with SQL language"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHvIwXR_rujV"
      },
      "source": [
        "weather_df.createOrReplaceTempView(\"weather\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3n9rLWerujW"
      },
      "source": [
        "temperature_averages = spark.sql(\"SELECT WBANNO, avg(T_HR_AVG) FROM weather GROUP BY WBANNO\").toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}